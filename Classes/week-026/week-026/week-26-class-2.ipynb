{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mature-attribute",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1 >Week 26 Class 2 03/23</h1>\n",
    "</div>\n",
    "\n",
    "## Objectives for this week:\n",
    "* Work on our projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-radical",
   "metadata": {},
   "source": [
    "# **Notes on our projects:**\n",
    "\n",
    "\n",
    "### **Data Engineering**\n",
    "\n",
    "* Find data from a source from a web source and scrape it. Alternatively you can choose to pull data from a source already formatted (csv, sql, etc). If you go the non-scraping route, you will have to compile multiple datasets together into one dataset. This will require you joining your data via SQL or pandas.\n",
    "* Clean up the data and organize it in a way that makes it useful. Make sure the data is correct, there is no missing data and that your columns and rows are properly formatted/labels. \n",
    "* Store your data in an sql database and create a flask api to access this data. The code that enters information into your sql database does not have to be the same code for your flask application (similar to what we did last phase). Your flask application only has to have routes for `GET` requests so that if deployed to a server, your data could be accessed.\n",
    "* Automate this entire process so that data can be pulled frequently. Your API must update when new information is pulled. Ideally this would be a locally based web application that when launched, you could see the latest data from your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-dance",
   "metadata": {},
   "source": [
    "### **Data Analysis**\n",
    "  - Come up with a research goal and do some initial research pertaining to the topic. This initial research will be the basis of your search for data. You must know what you need to have in order to research more about your topic. Once you know a bit about the topic, use this knowledge to find datasets that will help you with your research goal. This process of investigating and coming up with a research goal will form the introduction of your report. \n",
    "  - Form a hypothesis based on this research and set out to prove/disprove it with the data you will gather. Think about what data you need for this hypothesis, what sort of issues might you have and how you can address them.\n",
    "  - Find relevant data and clean it up so that it can be used for your purposes. Try to find actionable data that can provide insight into your research goal. Use visualizations to that communicates what sort of data you have and how it can be used.\n",
    "  - Perform exploratory analysis of this data in order to gather insights into your data that is related to your hypothesis. If more information is needed, find it and use it in your analysis. Document your process and report your findings.\n",
    "  - If doing a business intelligence based project, you must come up with a research goal related to a business' specific needs and you will need to structure your final report so that the business can take action based on your findings.\n",
    "  \n",
    "### Your final report will be in the following structure:\n",
    "* Introduction\n",
    "  - Summarize your initial research, your data analysis goal, the purpose of the report and summarize the data / subject.\n",
    "  - Include important contextual information about the reason for the report.\n",
    "  - Summarize your analysis questions, your conclusions, and briefly outline the report.\n",
    "* Body - Four Sections\n",
    "  - Data Section - Include written descriptions of data and follow with relevant dataframes.\n",
    "  - Methods Section - Explain how you gathered and analyzed data.\n",
    "  - Analysis Section - Explain what you analyzed. Include any charts here.\n",
    "  - Results - Describe the results of your analysis.\n",
    "\n",
    "* Conclusions\n",
    "  - Restate the questions from your introduction.\n",
    "  - Restate important results.\n",
    "  - Include any recommendations for additional data as needed.\n",
    "\n",
    "* Appendix\n",
    "  - Include the details of your data and process here. \n",
    "  - Include any secondary data, including references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-leader",
   "metadata": {},
   "source": [
    "### **Machine Learning:**\n",
    "\n",
    "  - If done solo, you will also need to find data, clean it up (if needed), do some feature engineering on the data so it's usable for your machine learning analysis and perform exploratory analysis. \n",
    "  - You will also have to come up with a research goal and form a hypothesis based on wanting to make predictions or classifying the data in some way. You are free to use machine learning algorithms not covered in class but linear/logistic regression analysis is expected.\n",
    "  - Document your process and report your findings (see previous section). After training your model make sure you perform the relevant testing of said model and include your results in your report. Use visualizations liberally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-crowd",
   "metadata": {},
   "source": [
    "# Solo Projects\n",
    "\n",
    "If you're doing the project solo, the grading is as follows:\n",
    "\n",
    "Data Engineering:\n",
    "- Pulling the data via python code [33%]\n",
    "- Code that processes the data and stores it to an SQL database [33%]\n",
    "- Web application that can access this data. [33%]\n",
    "\n",
    "Data Analysis and Machine Learning:\n",
    "- Your final report [100%]\n",
    "  * Introduction [20%]\n",
    "  * Body [60%]\n",
    "    - Data Section [15%]\n",
    "    - Methods Section [5%]\n",
    "    - Analysis Section [30%]\n",
    "    - Results Section [10%]\n",
    "  * Conclusion/Appendix [20%]  \n",
    "\n",
    "Note: Your final report will be a jupyter notebook with proper formatting, pictures/charts and other information. Make your notebook as nice as possible. In professional settings, these sorts of reports will be used by non-technical people so make sure its easily understood and organized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-finding",
   "metadata": {},
   "source": [
    "# Group Projects\n",
    "\n",
    "Each role will be graded using the above rubric. However each role will be graded as 33% (with the final report counting twice). Any group should contact teaching staff with information about your group members and roles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-proposal",
   "metadata": {},
   "source": [
    "# Data Sources:\n",
    "\n",
    "Here is a list of sources for data (in no particular order):\n",
    "* [Congress data](https://github.com/unitedstates/congress-legislators)\n",
    "* [The World Bank](http://data.worldbank.org/topic/private-sector)\n",
    "* [U.S. Census Data](http://www.census.gov/data/developers/data-sets.html)\n",
    "* [Jeopardy Data](http://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)\n",
    "* [r/datasets](http://www.reddit.com/r/datasets/)\n",
    "* [Pew Research Center's Internet Project](http://www.pewinternet.org/datasets/pages/3/)\n",
    "* [Public Datasets on AWS](https://aws.amazon.com/datasets?_encoding=UTF8&jiveRedirect=1)\n",
    "* [John Hopkin's Covid Data](https://github.com/CSSEGISandData/COVID-19)\n",
    "* [538 data](https://github.com/fivethirtyeight/data)\n",
    "* [NYT Covid Data](https://github.com/nytimes/covid-19-data)\n",
    "  - also [NYT data](http://data.nytimes.com/)\n",
    "* [Harvard Election Data](https://guides.library.harvard.edu/hks/campaigns_elections)\n",
    "* [Kaggle datasets](https://www.kaggle.com/datasets)\n",
    "* [Python Library for downloading yahoo finance data](https://github.com/ranaroussi/yfinance)\n",
    "* [FRED Economic Data from the Federal Reserve](https://fred.stlouisfed.org/)\n",
    "  - also [python library to access FRED](https://github.com/mortada/fredapi)\n",
    "* [CORGIS - Collection of Really Great, Interesting, Situated Datasets](https://corgis-edu.github.io/corgis/csv/)\n",
    "* [Basketball Statistics](https://www.basketball-reference.com/)\n",
    "* [Football Statistics](https://www.pro-football-reference.com/)\n",
    "* [Soccer Data](https://fbref.com/en/)\n",
    "* [Baseball Data](https://www.baseball-reference.com/)\n",
    "* [data.gov](https://www.data.gov/)\n",
    "* [Africa Open Data](https://africaopendata.org/dataset)\n",
    "* [NYS Educational Data](https://data.nysed.gov/downloads.php)\n",
    "* [NYC Open Data](https://opendata.cityofnewyork.us/)\n",
    "* [Microsoft Open Data](https://msropendata.com/)\n",
    "* [Quandl Data](https://www.quandl.com/)\n",
    "* [Internet Archive Open Library](https://openlibrary.org/developers/dumps)\n",
    "* [Datahub Data Search Engine](https://datahub.io/search)\n",
    "* [Bureau of Justice Statistics](https://www.bjs.gov/content/dtdata.cfm)\n",
    "* [NYPD Officer Complaint Database](https://www1.nyc.gov/site/ccrb/policy/MOS-records.page)\n",
    "* **[Awesome Data on github](https://github.com/awesomedata/awesome-public-datasets)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-packing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
